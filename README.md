# BrusselsHyperSonnet

An HCI transmedia poem in #VectorProsody (under construction)

MARGENTO

Brussels. A Human-Computer-Interaction Hypersonnet

Technics

A small corpus of 14 poems (guidance corpus) is put together while walking around downtown Brussels and a couple of the city’s “communes.” Since the model deployed involves representing texts as vectors based on the embeddings* of all the terms occurring in them (irrespective of their order or syntax), the poems written during those wanderings begin as lists of words. These lists are then transposed into concrete forms that expand their contents by means of quantum (mis)spelling making possible multidirectional readings and thus shaping them into linguistic mapping apps. We keep refining them till their vector-based similarity to the corresponding poem in the guidance corpus goes beyond a certain threshold (0.85 in our case). We need then a route across these maps, and since they were created by [dis]placing the guidance corpus poems, for each of the latter we find the list/concrete poem with the most similar vector. Surprisingly, this most similar poem is not always the one that was created by (dis)placing the corresponding guidance corpus one. The resulting sequence will represent our tour.
The code is available on GitHub [in this repo] and can be run on any other textual corpora, one just needs to switch to the relevant word embeddings in case their experiment is done in another language. For bi/multi-lingual experiments, please see the code written for “Cannes. A Bilingual Corpus Journey” (forthcoming). 

*We are using the FastText word embeddings trained on Facebook data.  



Poetics Statement 

Walking down the street—-after an endless lockdown—-we got a number of things to keep a (ravenous) eye on. First, materials and their chaotic-atomic algorithmic way of amassing; second, a corpus of poems assembled as augmented reality (AR) guidance in strolling; third, the emerging concrete shape of the poem as linguistic mapping app; and, fourth, the poetic vector meter of the resulting poem(s) and its/their similarity to the vectors of the poems in the above-mentioned AR app. The latter helps to work on the emerging poem(s) and then draw a route or tour crossing all poems in the resulting corpus according to their vector similarities to poems in the guiding corpus. 

Materials. We walk randomly around the neighborhood, around the poem, as we know that syntax has little if any actual influence on the resulting poetic vector meter. It’s a list of words or n-grams we’re therefore putting together, not sentences or lines, in no particular order, just an avalanche of words or stock phrases that will later on be translated into the emergent poem’s vector. As natural language processing (NLP) algorithms—-Johanna Drucker made the distinction between thinking like and as an algorithm—-we will feed on “bags of words.” But then as a data scrapers as well, we’re throwing words into that same bag. And we’re thus already cheating: processing data while, and even before, collecting it… Collection is geared for, biased towards, and ultimately informed by, processing.

Guidance corpus. We also walk through a dataset. A corpus of poems we’ve been collecting and reading recently as guidance in our wanderings. Guidance and fluid evolving frame of reference at the same time. It actually works as a  ‘mental’ AR app popping up before our eyes in the process of translating (scraping and processing) what we see as we walk. Translation or app or both are shaped in the process. While translation generates both the ‘original’ and the ‘translation,’ the AR does not presuppose a constant or self-contained R either. Rather, AR and R search through/with, and thus shape, each other in the process. Poems are picked for guidance in a specific spot, are de/re/trans-formed, or added to the guidance corpus as we go along, while what we scrape, what we (choose) to see is grounded in those poems. 

Form. A fundamental concept in terms of form is “vector prosody” (defined and detailed in “Cannes. A Bilingual Corpus Journey”). In this particular case, the vector meter of a poem means the vector representing the poem as a whole. Given the type of meter used here, computationally speaking the poem is simply the “bag of words” it contains, representable as a (Python) list the indices of which—and therefore the order of words, alongside the poem’s syntax—do not really impact the poem’s vector. Yet there is another formal aspect that is order and topology-sensitive. Namely, the concrete design of the poem as topographic instrument used in shaping both place and language, and thus instrumental in developing the poem itself and adjusting its vector so that it gets closer and closer to the corresponding poem in the guidance corpus. 

Maths. Our code computes (iteratively, where needed) the similarity between the emerging poem’s vector and that of the guidance corpus poem involved in mapping the place we loiter about at the time of ‘writing.’ This computation is in fact part of the composition process, crucially impacting the poem’s form (described, therefore, as vector prosody) and informing the topology and optimal tour across the resulting corpus. It is not only the poetry of place involved that intertwines mapping and touring into a dynamic performative topophrenia (Robert T. Tally’s term). It is also the mathematics of poetic form transitioning from digits to the digital (or rather submerging the former into the latter) that accomplishes that in mapping and crossing vector and ‘real-life’ spaces alike. The poet’s—-Goethe or, more recently, Martin Woodside’s—-fingers tapping the poem’s beat on the lover’s back meanwhile (also) type in, and rhythmically run, the iterations computing the growing poem’s evolving vector meter. The language and form mutual shaping process involve now a space-modeling mathematics of place exploration-generation. 
